import streamlit as st
from gpt import bot
from streamlit_tags import st_tags
from sentence_formation import word_formater
import random
import time
import spacy
import json
import re
from deta import Deta
from streamlit_extras.grid import grid
from dotenv import load_dotenv
import os
from input_field_component import input_field
from better_profanity import profanity


#–ù–µ–æ–±—Ö–æ–¥–∏–º—ã–π –º–æ–¥—É–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–∞–≤–æ–ø–∏—Å–∞–Ω–∏—è

from spellchecker import SpellChecker
spell = SpellChecker()

#–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–Ω–µ—à–µ–Ω–≥–æ –≤–∏–¥–∞ —Å—Ä–∞–Ω–∏—Ü—ã, —Å–∫—Ä—ã—Ç–∏–µ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö —ç–µ–ª–µ–º–µ–Ω—Ç–æ–≤

st.set_page_config(
    page_title="LexisGen",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="auto"
)

st.markdown("""
<style>
    div[data-testid="stToolbar"] { display: none;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)


load_dotenv()

#–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

base_key = os.getenv('DATABASE_KEY')
deta = Deta(base_key)
database = deta.Base("users")


# –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞–º–∏
@st.cache_data(show_spinner=False)
def load_contexts():
    with open('./contexts.json') as json_file:
        data = json.load(json_file)
    return data

contexts = load_contexts()

# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
@st.cache_resource
def load_dictionary(dict_type):
    nlp = spacy.load(dict_type)
    return nlp

nlp = load_dictionary("en_core_web_sm")

#–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç, —Ñ–ª–∞–≥–æ–≤ –∏ –∫–æ–ª–ª–µ–∫—Ü–∏–π –¥–∞–Ω–Ω—ã—Ö
main_prompt = '''You are provided with a list of words and contexts, and you should generate a list of sentences at elementary English level, where the mentioned words are used in the appropriate context. When making sentences, follow these requirements:
1. Form of these words remain unchanged.
2. You have to provide only one sentence for each word and nothing else.
3. These words are not replaced with synonyms.
4. Each sentence must contain at least 20 words.'''

if "define_initial_values" not in st.session_state:
    st.session_state.define_initial_values = True

if "data" not in st.session_state:
    st.session_state.data = [{"role": "system", "content": main_prompt}]

if "level" not in st.session_state:
    st.session_state.level = "middle"

if "stop_words" not in st.session_state:
    st.session_state.stop_words = ["a", "an", "the", "to", "be", "being", "have", "having", "has", "been", "was", "were", "will", "could", "would", "may", "might", "ought", "by", "at", "as", "on", "for", "is", "are", "of", "in", "did", "does", "didn't", "doesn't", "about", "into", "around", "couldn't", "wasn't", "weren't", "won't", "not"]

if "propriate_length" not in st.session_state:
    st.session_state.propriate_length = True

if "propriate_spell" not in st.session_state:
    st.session_state.propriate_spell = True

if "responses" not in st.session_state:
    st.session_state.responses = []

if "formated_responses" not in st.session_state:
    st.session_state.formated_responses = []

if "number_of_sentenses" not in st.session_state:
    st.session_state.number_of_sentenses = 0

if "answers" not in st.session_state:
    st.session_state.answers = []

if "unique_key" not in st.session_state:
    st.session_state.unique_key = 0

if "user_answers" not in st.session_state:
    st.session_state.user_answers = {}

if "check_answers" not in st.session_state:
    st.session_state.check_answers = False

if "check_language" not in st.session_state:
    st.session_state.check_language = True

if "not_in_sw" not in st.session_state:
    st.session_state.not_in_sw = True

if "key_is_provided" not in st.session_state:
    st.session_state.key_is_provided = False
    
if "tokens" not in st.session_state:
    st.session_state.tokens = 0

if "collections" not in st.session_state:
    st.session_state.collections = []

if "show_answers_form" not in st.session_state:
    st.session_state.show_answers_form = False

if "results" not in st.session_state:
    st.session_state.results = []

if "gens_number" not in st.session_state:
    st.session_state.gens_number = 0

if "show_submit_form" not in st.session_state:
    st.session_state.show_submit_form = False

if "allow_generation" not in st.session_state:
    st.session_state.allow_generation = False

if "error_item" not in st.session_state:
    st.session_state.error_item = ""

if "input_item" not in st.session_state:
    st.session_state.input_item = ""

if "initial_values" not in st.session_state:
    st.session_state.initial_values = []

if "acsses_key" not in st.session_state:
    st.session_state.acsses_key = ""

if "swearword" not in st.session_state:
    st.session_state.swearword = ""

if "suggestion" not in st.session_state:
    st.session_state.suggestion = ""

if "wordnotexist" not in st.session_state:
    st.session_state.wordnotexist = ""

if "notenought" not in st.session_state:
    st.session_state.notenought = ""

if "impossibleword" not in st.session_state:
    st.session_state.impossibleword = ""

if "propriate_spell" not in st.session_state:
    st.session_state.propriate_spell = True

if "propriate_length" not in st.session_state:
    st.session_state.propriate_length = True

if "profanity" not in st.session_state:
    st.session_state.profanity = False

with st.sidebar:


    if acsses_key := st.text_input("–ö–ª—é—á –¥–æ—Å—Ç—É–ø–∞", type="password", autocomplete=""):
        if acsses_key != "":
            @st.cache_data()
            def check_acsses_key(token):
                if database.get(token) != None:

                    key_is_provided = True
                    return key_is_provided
                else:
                    key_is_provided = False
                    return key_is_provided
            st.session_state.key_is_provided = check_acsses_key(acsses_key)

            if st.session_state.key_is_provided:
                data = database.get(acsses_key)

                st.session_state.acsses_key = data["access_key"]


                st.session_state.gens_number = data["gens_number"]

            else:
                    st.warning("–ö–ª—é—á –¥–æ—Å—Ç—É–ø–∞ –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω, –ª–∏–±–æ –≤–≤–µ–¥—ë–Ω –Ω–µ–≤–µ—Ä–Ω–æ")
        else:
            st.session_state.key_is_provided = False
    else:
        st.session_state.key_is_provided = False

main_grid = grid([2, 4.5, 2])

main_grid.write("")

with main_grid.container():

    st.markdown('<h1 style="text-align:center">LexisGen</h1>', unsafe_allow_html=True)

    st.write("")
    st.write("")

    with st.form("words input"):
        if "keywords" not in st.session_state:
            st.session_state.keywords = []

        text, maxtags = ('–ù–∞–∂–º–∏—Ç–µ Enter, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å —Å–ª–æ–≤–æ', 8)

        st.subheader("–í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–∞:", anchor=False)

        if keywords := st_tags(label="", text=text, value=[], maxtags = 8, key='keyword'): 
            st.session_state.keywords = keywords

            st.session_state.propriate_spell = True
            st.session_state.propriate_length = True
            st.session_state.profanity = False

        #–æ—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º—ã
        if st.form_submit_button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å"):
            for item in st.session_state.keywords:

                #–ø—Ä–æ–≤–µ—Ä–∫–∞, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ –∫ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º—É —è–∑—ã–∫—É

                reg = re.compile(r'[a-zA-Z]')
                if reg.match(item.lower()):
                    st.session_state.check_language = True
                else:
                    st.session_state.check_language = False
                    st.session_state.input_item = item

                    break

                # –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –≤–≤–µ–¥–µ–Ω–æ–≥–æ —Å–ª–æ–≤–∞ 
                # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –Ω–∞–ø–∏—Å–∞–Ω–æ –Ω–µ–≤–µ—Ä–Ω–æ, —Ç–æ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, –µ—Å–ª–∏ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–µ—Ç - —É–∫–∞–∑–∞—Ç—å, —á—Ç–æ —Ç–∞–∫–æ–≥–æ —Å–ª–æ–≤–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

                try:
                    temp = item.lower().replace('-', " ")
                    temp = temp.split()
                    misspelled = spell.unknown(temp)
                    if len(misspelled) > 0:
                        st.session_state.propriate_spell = False
                        for w in misspelled:
                            i = temp.index(w)
                            temp[i] = spell.correction(w)
                    
                        st.session_state.wordnotexist = item
                        st.session_state.suggestion = " ".join(temp)

                        break
                except:
                    st.session_state.propriate_spell = "impossible_word"
                    st.session_state.impossibleword = item

                    break


                # –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–æ—Ä–∞–ª—å–Ω–æ-—ç—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å–≤–∏–µ

                if profanity.contains_profanity(item.lower()):
                    st.session_state.profanity = True
                    st.session_state.swearword = item
                    break
                #–ø—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –≤–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–ª–æ–≤–æ—á–µ—Ç–∞–Ω–∏–µ–º –∏–ª–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–ª–æ–≤–æ–º

                if len(item.split()) > 1:
                    t = 0
                    for w in item.split():
                        if w.lower() in st.session_state.stop_words:
                            continue
                        else:
                            t += 1
                    if t > 1:
                        st.session_state.propriate_length = False
                        st.session_state.error_item = item

                        break

                #–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¢–æ–ª—å–∫–æ –∫ —Å–ø–∏—Å–∫—É —Å—Ç–æ–ø-—Å–ª–æ–≤

                if item.lower().strip() in st.session_state.stop_words:
                    st.session_state.not_in_sw = False
                    st.session_state.notenought = item

                    break
                else:
                    st.session_state.not_in_sw = True

            if st.session_state.propriate_length and st.session_state.propriate_spell == True and st.session_state.check_language and st.session_state.not_in_sw and len(st.session_state.keywords) >= 2 and st.session_state.gens_number > 0 and not st.session_state.profanity:
                st.session_state.allow_generation = True
            else:
                st.session_state.allow_generation = False

            if st.session_state.key_is_provided:
                if st.session_state.allow_generation:

                    st.session_state.responses.clear()
                    st.session_state.formated_responses.clear()
                    st.session_state.answers.clear()
                    st.session_state.user_answers.clear()
                    st.session_state.url_q = 0
                    st.session_state.check_answers = False
                    st.session_state.data = [{"role": "system", "content": main_prompt}]
                    st.session_state.results = ""
                    st.session_state.error_item = ""
                    st.session_state.input_item = ""
                    st.session_state.suggestion = ""
                    st.session_state.wordnotexist = ""
                    st.session_state.impossibleword = ""
                    st.session_state.swearword = ""
                    st.session_state.notenought = ""

                    prompt = ""
                    for i in range(len(st.session_state.keywords)):

                        # prompts = {"middle": f'''{i  + 1}.Make up a sentence at elementary English level with the word "{st.session_state.keywords[i].lower()}". Add the context of {contexts[str(random.randint(0, 515))].lower()}. The sentence lenght must be up to 26 words. Do not change the initial form of "{st.session_state.keywords[i].lower()}".'''}
                        prompts = {"middle": f'''{i  + 1}. Word - {st.session_state.keywords[i].lower()}, context - {contexts[str(random.randint(0, 515))].lower()}.'''}
                        prompt += prompts[st.session_state.level]+"\n"

                    
                    # time.sleep(2)
                    st.session_state.data.append({"role": "user", "content": prompt})

                    try:
                        with st.spinner('–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è...'):
                            url = "https://api.theb.ai/v1/chat/completions"
                            res = bot(st.session_state.data, url, st.session_state.acsses_key, 1)

                            response = res[0]
                            st.session_state.tokens = res[1]
                            st.session_state.data.append({"role": "assistant", "content": response})

                            list_of_sentences = response.split("\n")

                            for word in list_of_sentences:
                                if word == "":
                                    i = list_of_sentences.index(word)
                                    del list_of_sentences[i]

                            status = True
                            for i in range(len(st.session_state.keywords)):

                                item = st.session_state.keywords[i]
                                sentence = list_of_sentences[i]

                                st.session_state.unique_key += 1
                                st.session_state.responses.append(list_of_sentences[i])
                                st.session_state.formated_responses.append([word_formater(item, sentence)[0], word_formater(item, sentence)[2]])

                                if word_formater(item, sentence)[3]:
                                    pass
                                else:
                                    status = False

                            if status:
                                gens_number = int(data["gens_number"])
                                updated_value = gens_number - 1
                                database.update({"gens_number": updated_value}, acsses_key)

                                st.session_state.gens_number = updated_value

                            st.session_state.number_of_sentenses = len(st.session_state.responses)

                            random.shuffle(st.session_state.formated_responses)

                            st.session_state.show_submit_form = True
                    except:
                        try:
                            with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è..."):
                                url = "https://api.baizhi.ai/v1/chat/completions"
                                res = bot(st.session_state.data, url, st.session_state.acsses_key, 1)
                        
                                response = res[0]
                                st.session_state.tokens = res[1]
                                st.session_state.data.append({"role": "assistant", "content": response})

                                list_of_sentences = response.split("\n")

                                for word in list_of_sentences:
                                    if word == "":
                                        i = list_of_sentences.index(word)
                                        del list_of_sentences[i]

                                status = True
                                for i in range(len(st.session_state.keywords)):

                                    item = st.session_state.keywords[i]
                                    sentence = list_of_sentences[i]

                                    st.session_state.unique_key += 1
                                    st.session_state.responses.append(list_of_sentences[i])
                                    st.session_state.formated_responses.append([word_formater(item, sentence)[0], word_formater(item, sentence)[2]])

                                    if word_formater(item, sentence)[3]:
                                        pass
                                    else:
                                        status = False

                                if status:
                                    gens_number = int(data["gens_number"])
                                    updated_value = gens_number - 1
                                    database.update({"gens_number": updated_value}, acsses_key)

                                    st.session_state.gens_number = updated_value

                                st.session_state.number_of_sentenses = len(st.session_state.responses)

                                random.shuffle(st.session_state.formated_responses)

                                st.session_state.show_submit_form = True
                        except:
                            st.error("–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å —Å–µ—Ä–≤–µ—Ä–æ–º –ø—Ä–µ—Ä–≤–∞–Ω–æ, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ–∑–¥–∞—Ç—å –∑–∞–¥–∞–Ω–∏–µ –µ—â–µ —Ä–∞–∑.\n –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –ø–æ—è–≤–ª—è—Ç—å—Å—è, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ —Ç–µ—Ö. –ø–æ–¥–¥–µ—Ä–∂–∫—É!", icon="üíî")
                else:

                    if st.session_state.gens_number == 0:
                        st.warning(" &nbsp; –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —á–∏—Å–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π –∏—Å—á–µ—Ä–ø–∞–Ω–æ, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—é LexisGen, —á—Ç–æ–±—ã –ø–æ–ø–æ–ª–Ω–∏—Ç—å –µ–≥–æ", icon="üòî")
                    if len(st.session_state.keywords) < 2:
                        st.warning(" &nbsp; –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã 2 —Å–ª–æ–≤–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–¥–∞–Ω–∏—è", icon="üôä")
                    if st.session_state.propriate_length == False:
                        st.warning(f'  &nbsp; "{st.session_state.error_item}" –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏–π, —Ñ—Ä–∞–∑ –∏–ª–∏ –∏–¥–∏–æ–º. –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø–æ–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ–ª—å–∫–æ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤.', icon="‚ö†Ô∏è")
                    if st.session_state.check_language == False:
                        st.info(f' &nbsp; "{st.session_state.input_item}" –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–æ–º, –æ—Ç–Ω–æ—Å—è—â–∏–º—Å—è –∫ –ê–Ω–≥–ª–∏–π—Å–∫–æ–º—É —è–∑—ã–∫—É', icon="üåê")
                    if st.session_state.propriate_spell == "impossible_word" and st.session_state.check_language:
                        st.warning(f' &nbsp; –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –Ω–µ —Å–º–æ–≥–ª–∞ –¥–æ–≥–∞–¥–∞—Ç—å—Å—è, —á—Ç–æ –í—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É –ø–æ–¥ "{st.session_state.impossibleword}"...', icon="üò¢")
                    if st.session_state.propriate_spell == False:
                        st.warning(f'  &nbsp; –°–ª–æ–≤–∞ "{st.session_state.wordnotexist}" –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –í–æ–∑–º–æ–∂–Ω–æ, –í—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É "{st.session_state.suggestion}"?', icon="‚ö†Ô∏è")
                    if st.session_state.not_in_sw == False:
                        st.warning(f'  &nbsp; –¢–æ–ª—å–∫–æ "{st.session_state.notenought}" –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è...', icon="üòï")
                    if st.session_state.profanity:
                        st.warning(f' &nbsp; "{st.session_state.swearword}" - –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω–∞—è –∏–ª–∏ –æ—Å–∫–æ—Ä–±–∏—Ç–µ–ª—å–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º–∞!', icon='üò∂')
            else:
                st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–ª—é—á –¥–æ—Å—Ç—É–ø–∞", icon="üîë")

    if st.session_state.show_submit_form:
        # st.info('–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–æ–ø—É—Å–∫–∏ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –Ω–∏–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º–æ–π —Å–ª–æ–≤–∞ –∏–∑ —Å–ø–∏–∫–∞ –≤—ã—à–µ.')
        st.info('–í–≤–µ–¥–µ–Ω–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–æ–ø—É—Å–∫–∏ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –Ω–∏–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ.')

        with st.form("my_form"):

            if len(st.session_state.answers) == 0:
                for answer in st.session_state.formated_responses:
                    st.session_state.answers.append(answer[1])

            
            for i in range(st.session_state.number_of_sentenses):
                try:
                    time.sleep(0.15)
                    st.session_state.user_answers[i] = input_field(st.session_state.formated_responses[i][0], key=st.session_state.unique_key + i)
                except:
                    pass

            if st.form_submit_button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å"):
                try:
                    st.session_state.results = ""
                    for i in range(len(st.session_state.user_answers)):
                        if len(st.session_state.user_answers[i]) != 0:
                            if st.session_state.user_answers[i][0].lower() == st.session_state.answers[i].lower():
                                st.session_state.results += f" ‚úîÔ∏è :green[{st.session_state.answers[i].lower()}]"
                            elif len(st.session_state.user_answers[i][0].strip()) > 0:
                                st.session_state.results += f" ‚ùå :red[{st.session_state.user_answers[i][0].lower()}]"

                    st.write(st.session_state.results)
                except:
                    pass

        with st.expander("–û—Ç–≤–µ—Ç—ã"):
            for i in range(st.session_state.number_of_sentenses):
                try:
                    st.write(st.session_state.formated_responses[i][0].replace("[G_A_P]", f":blue[{st.session_state.answers[i]}]"))
                except:
                    pass
        # st.write(st.session_state.tokens)


main_grid.write("")

with st.sidebar:
    if st.session_state.key_is_provided:
        st.title(f"–û—Å—Ç–∞–ª–æ—Å—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–π: {st.session_state.gens_number}")


    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")
    st.write("")


    st.link_button("‚ö° –ü–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø", "https://vk.com/@lexisgen-kak-poluchit-dostup")
    st.link_button("üîó –°–æ–æ–±—â–µ—Å—Ç–≤–æ –≤ –í–ö", "https://vk.com/lexisgen")
    st.link_button("‚öôÔ∏è –¢–µ—Ö. –ø–æ–¥–¥–µ—Ä–∂–∫–∞ &nbsp; &nbsp;", "https://vk.com/lostconcepts")